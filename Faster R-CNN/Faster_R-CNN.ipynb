{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note:** For better usability `Training` and `Testing` sections should be placed in seperate source files. Furtheremore some functions like `getModel` are defined twice. Once in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, to install PyTorch the command below was used since it download `PyTroch with Cuda compatability` which allowed the model to run on GPU instead of CPU which `helped decrease execution time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image/s to tensor\n",
    "class CocoToTensor:\n",
    "    def __call__(self, image, target):\n",
    "        # Convert PIL image to tensor\n",
    "        image = functional.to_tensor(image)\n",
    "        \n",
    "        # return image and target - target mean the class name and bounding box\n",
    "        return image, target\n",
    "\n",
    "# Load the COCO dataset\n",
    "def get_dataset(img_dir, ann_file):\n",
    "    # Load the COCO dataset\n",
    "    return CocoDetection(\n",
    "        root=img_dir, \n",
    "        annFile=ann_file, \n",
    "        transforms=CocoToTensor()\n",
    "    )\n",
    "\n",
    "# Function to load Faster R-CNN with ResNet50 backend\n",
    "def getModel(numOfClasses):\n",
    "    # Load pre-trained Faster R-CNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    input_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(input_features, numOfClasses)\n",
    "    \n",
    "    # Return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training One Epoch Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def trainEpoch(model, optimizer, data_loader, device, epoch):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the data\n",
    "    for batch_index, (images, targets) in enumerate(data_loader):\n",
    "        if (batch_index + 1) == (len(data_loader)):\n",
    "            print(f\"Processing Batch {batch_index + 1}/{len(data_loader)}\")\n",
    "        else:\n",
    "            print(f\"Processing Batch {batch_index + 1}/{len(data_loader)}\", end='\\r')\n",
    "\n",
    "        # Move images to device\n",
    "        images = [img.to(device) for img in images]\n",
    "        \n",
    "        # Validate and process targets\n",
    "        processed_targets = []\n",
    "        valid_images = []\n",
    "        \n",
    "        # Iterate over targets\n",
    "        for i, target in enumerate(targets):\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            \n",
    "            for obj in target:\n",
    "                # Extract bounding box coordinates\n",
    "                bbox = obj['bbox']  # [x, y, width, height]\n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                # Validate width and height are positive\n",
    "                if w > 0 and h > 0:\n",
    "                    boxes.append([x, y, x + w, y + h])  # Convert to [x_min, y_min, x_max, y_max]\n",
    "                    labels.append(obj['category_id'])\n",
    "                    \n",
    "            # If valid boxes\n",
    "            if boxes:\n",
    "                processed_target = {\n",
    "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),  # Corrected key\n",
    "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "                }\n",
    "                processed_targets.append(processed_target)\n",
    "                valid_images.append(images[i])\n",
    "        \n",
    "        # Skip iteration if no valid targets\n",
    "        if not processed_targets:\n",
    "            print(f\"Batch {batch_index + 1}: No valid targets, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure alignment of images and targets\n",
    "        images = valid_images\n",
    "        \n",
    "        # Forward pass\n",
    "        loss_dict = model(images, processed_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch + 1}] Loss: {losses.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset and Creating DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n----- <Loading Training Dataset> -----\")\n",
    "# Load training and validation data\n",
    "training_data = get_dataset(\n",
    "    img_dir='./trashy-dataset-roboflow.coco/train', \n",
    "    ann_file='./trashy-dataset-roboflow.coco/train/_annotations.coco.json'\n",
    ")\n",
    "print(f\"----- <Dataset Loaded Successfully> -----\")\n",
    "\n",
    "# Create two respective dataloaders\n",
    "print(f\"\\n----- <Creating Training DataLoader> -----\")\n",
    "training_dataloader = DataLoader(training_data, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "print(f\"----- <DataLoader Created Successfully> -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Faster R-CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "numOfClasses = 5 # Background, Mixed Waste -Black Bag-, Organic Waste -White Bag-, Other, Recycled Waste -Grey or Green Bag-\n",
    "\n",
    "# Initialise the Model\n",
    "model = getModel(numOfClasses)\n",
    "\n",
    "# Move model to device if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)} is available - moving model to GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU available. Moving training to CPU.\")\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyperparameters and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and hyperparameters\n",
    "num_epochs = 100\n",
    "parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "optimiser = torch.optim.SGD(parameters, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "learningRate_scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"\\n----- <Training Model> -----\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n----- <Starting Epoch {epoch + 1}/{num_epochs}> -----\")\n",
    "    trainEpoch(model, optimiser, training_dataloader, device, epoch)\n",
    "    learningRate_scheduler.step()\n",
    "    \n",
    "    # Save model's if it's the last epoch\n",
    "    if (epoch + 1) == num_epochs:\n",
    "        # Create output directory if it doesn't exist\n",
    "        outputFolder = './Faster_R-CNN - Saved_Model'\n",
    "        \n",
    "        if not os.path.exists(outputFolder):\n",
    "            os.makedirs(outputFolder)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = f\"{outputFolder}/model_epoch{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}: Model saved at {model_path}\")\n",
    "    \n",
    "print(f\"\\n----- <Training Completed Successfully> -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load Faster R-CNN with ResNet50 backend\n",
    "def getModel(numOfClasses):\n",
    "    # Load pre-trained Faster R-CNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    input_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(input_features, numOfClasses)\n",
    "    \n",
    "    # Return model\n",
    "    return model\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(img_path, device):\n",
    "    # Open image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Convert image to tensor and add batch dimension\n",
    "    img_tensor = functional.to_tensor(img).unsqueeze(0)\n",
    "    \n",
    "    # move image to device and return it\n",
    "    return img_tensor.to(device)\n",
    "\n",
    "# Get class name\n",
    "def get_class_name(class_id, COCO_CLASSES):\n",
    "    return COCO_CLASSES.get(class_id, 'Unknown') # return 'Unknown' if class_id not found\n",
    "\n",
    "\n",
    "# Function to load true labels from COCO annotations\n",
    "def load_coco_annotations(annotation_file, image_files):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    # Create a mapping of image ID to its annotations\n",
    "    image_id_to_annotations = {image['id']: [] for image in annotations['images']}\n",
    "    for annotation in annotations['annotations']:\n",
    "        image_id_to_annotations[annotation['image_id']].append(annotation['category_id'])\n",
    "\n",
    "    # Map file names to true labels\n",
    "    file_name_to_labels = {}\n",
    "    for image in annotations['images']:\n",
    "        file_name = image['file_name']\n",
    "        image_id = image['id']\n",
    "        true_labels = image_id_to_annotations[image_id]\n",
    "        file_name_to_labels[file_name] = true_labels\n",
    "\n",
    "    # Filter only the labels for images in the test set\n",
    "    true_labels = {img: file_name_to_labels[img] for img in image_files if img in file_name_to_labels}\n",
    "    return true_labels\n",
    "\n",
    "# Function to plot precision-recall curve and calculate AUC\n",
    "def plot_precision_recall(y_true, y_scores, num_classes, output_dir, COCO_CLASSES):\n",
    "    # Set up the figure size for the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Loop through each class and compute its precision-recall curve\n",
    "    for class_id in range(num_classes):\n",
    "        # Check if there are any positive examples for the class\n",
    "        if np.sum(y_true[:, class_id]) == 0:\n",
    "            print(f\"Warning: No positive samples found for class '{COCO_CLASSES[class_id]}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Compute precision, recall, and thresholds for the class\n",
    "        precision, recall, _ = precision_recall_curve(y_true[:, class_id], y_scores[:, class_id])\n",
    "\n",
    "        # Calculate the area under the precision-recall curve (AUC)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        # Plot the precision-recall curve for the class, including the AUC in the label\n",
    "        plt.plot(recall, precision, label=f\"{COCO_CLASSES[class_id]} (AUC = {pr_auc:.2f})\")\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Faster R-CNN - Precision-Recall Curve\")\n",
    "    # Add a legend to identify the curves by class\n",
    "    plt.legend(loc=\"best\")\n",
    "    # Add a grid for better readability\n",
    "    plt.grid()\n",
    "    # Save the plot as an image file\n",
    "    plt.savefig(f\"{output_dir}/precision_recall_curve_with_auc.png\")\n",
    "    # Close the plot to free up memory\n",
    "    plt.close('all')\n",
    "    \n",
    "# Function to plot a single confusion matrix with better formatting\n",
    "def plot_multiclass_confusion_matrix(y_true, y_pred, num_classes, output_dir, COCO_CLASSES):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1), labels=range(num_classes))\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Create a heatmap for the confusion matrix\n",
    "    heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                          xticklabels=COCO_CLASSES.values(), \n",
    "                          yticklabels=COCO_CLASSES.values(),\n",
    "                          annot_kws={\"size\": 14})  # Annotation font size\n",
    "\n",
    "    # Add titles and axis labels\n",
    "    plt.title(\"Faster R-CNN - Confusion Matrix\", fontsize=18)\n",
    "    plt.xlabel(\"True Labels\", fontsize=14)\n",
    "    plt.ylabel(\"Predicted Labels\", fontsize=14)\n",
    "    # Rotate the x-axis labels for better visibility\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(rotation=0, fontsize=12)\n",
    "    # Add a color bar label\n",
    "    colorbar = heatmap.collections[0].colorbar\n",
    "    colorbar.set_label(\"Count\", fontsize=12)\n",
    "    # Automatically adjust the layout to avoid truncation\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_dir, \"confusion_matrix_multiclass.png\"))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Draw Bounding Boxes on Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding box with correct class name and increase image size\n",
    "def draw_bboxes(output_dir, image, prediction, fig_size, COCO_CLASSES, saved_images_counter, total_images):\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy() # get predicted bounding boxes\n",
    "    labels = prediction[0]['labels'].cpu().numpy() # get predicted labels\n",
    "    scores = prediction[0]['scores'].cpu().numpy() # get predicted scores\n",
    "    \n",
    "    # Set a threshold for showing bounding boxes\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Create a figure and axes using subplots\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw bboxes\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        # check is score is above threshold\n",
    "        if score > threshold:\n",
    "            # Draw bbox\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            # Get class name\n",
    "            class_name = get_class_name(label, COCO_CLASSES)\n",
    "            \n",
    "            # Draw bbox\n",
    "            ax.add_patch(\n",
    "                plt.Rectangle(\n",
    "                    (x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                    fill=False, \n",
    "                    edgecolor='red', \n",
    "                    linewidth=2\n",
    "                )\n",
    "            )\n",
    "            # Add class name\n",
    "            ax.text(\n",
    "                x_min, y_min, \n",
    "                f'{class_name} ({score:.3f})', \n",
    "                color='blue', \n",
    "                fontsize=10,\n",
    "            )\n",
    "            \n",
    "    # Turn off axis\n",
    "    ax.axis('off')\n",
    "    # Saving plt using Image\n",
    "    fig.savefig(f'{output_dir}/{img}', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # ouput saved image number\n",
    "    if (saved_images_counter + 1) == (total_images - 1):\n",
    "        print(f\"Saved image {saved_images_counter + 1}/{total_images - 1}\")\n",
    "    else:\n",
    "        print(f\"Saved image {saved_images_counter + 1}/{total_images - 1}\", end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "fig_size = (8, 8)\n",
    "# Num of classes\n",
    "numOfClasses = 5 # Trash, Mixed Waste -Black Bag-, Organic Waste -White Bag-, Other, Recycled Waste -Grey or Green Bag-\n",
    "# COCO classes - 5 classes\n",
    "COCO_CLASSES = {0:'Trash', 1:'Mixed Waste -Black Bag-', 2:'Organic Waste -White Bag-', 3:'Other', 4:'Recycled Waste -Grey or Green Bag-'}\n",
    "# Get testing directory\n",
    "testing_dir = './trashy-dataset-roboflow.coco/test'\n",
    "# Output directories\n",
    "output_dir_images = './images'\n",
    "output_dir_plots = './plots'\n",
    "# saved images counter\n",
    "saved_images_counter = 0\n",
    "\n",
    "# Initialize lists for ground truth and predictions\n",
    "y_true_list = []\n",
    "y_scores_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Device Availability and Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the saved model\n",
    "saved_model_dir = './Faster_R-CNN - Saved_Model'\n",
    "# Get the path to the only file in the directory\n",
    "model_path = os.path.join(saved_model_dir, os.listdir(saved_model_dir)[0])\n",
    "\n",
    "\n",
    "# Move model to device if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)} is available - moving model to GPU\\n\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\\nNo GPU available. Moving training to CPU\\n\")\n",
    "\n",
    "# Initialise the Model\n",
    "print(\"----- <Loading Model> -----\")\n",
    "# Load trained model with weights_only=True\n",
    "model = getModel(numOfClasses)\n",
    "# Load the state dictionary (safe way)\n",
    "state_dict = torch.load(model_path, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "print(f\"----- <Model [{os.listdir(saved_model_dir)[0]}] Loaded Successfully> -----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Predictions For Each Test Image and Output To Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "if not os.path.exists(output_dir_images):\n",
    "    os.makedirs(output_dir_images)\n",
    "\n",
    "# Get all test images\n",
    "test_images = [img for img in os.listdir(testing_dir) if img != '_annotations.coco.json']\n",
    "\n",
    "# Load true labels from annotations\n",
    "true_labels = load_coco_annotations(\"./trashy-dataset-roboflow.coco/test/_annotations.coco.json\", test_images)\n",
    "    \n",
    "# Get all test images in the directory\n",
    "for img in os.listdir(testing_dir):\n",
    "    # If file is not _annotations.coco.json\n",
    "    if not img == '_annotations.coco.json':\n",
    "        # Get full image path\n",
    "        img_path = os.path.join(testing_dir, img)\n",
    "        # Convert image to tensor\n",
    "        image_tensor = preprocess_image(img_path, device)\n",
    "\n",
    "        # Disable gradient computation\n",
    "        with torch.no_grad():\n",
    "            # Get prediction\n",
    "            prediction = model(image_tensor)   \n",
    "            \n",
    "        true_label_indices = true_labels.get(img, [])\n",
    "        true_one_hot = np.zeros((1, numOfClasses))\n",
    "        \n",
    "        for idx in true_label_indices:\n",
    "            true_one_hot[0, idx] = 1\n",
    "\n",
    "        pred_scores = np.zeros(numOfClasses)\n",
    "        \n",
    "        for label, score in zip(prediction[0]['labels'].cpu().numpy(), prediction[0]['scores'].cpu().numpy()):\n",
    "            pred_scores[label] = max(pred_scores[label], score)\n",
    "\n",
    "        y_true_list.append(true_one_hot)\n",
    "        y_scores_list.append(pred_scores)\n",
    "    \n",
    "        # Display image with bounding boxes\n",
    "        draw_bboxes(output_dir_images, Image.open(img_path), prediction, fig_size, COCO_CLASSES, saved_images_counter, total_images=len(os.listdir(testing_dir)))\n",
    "        # Increment saved images counter\n",
    "        saved_images_counter += 1\n",
    "        \n",
    "        # Closing all figures to free up memory\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall and Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for plots\n",
    "if not os.path.exists(output_dir_plots):\n",
    "    os.makedirs(output_dir_plots)\n",
    "\n",
    "# Stack the true labels and predictions\n",
    "y_true = np.vstack(y_true_list)\n",
    "y_scores = np.vstack(y_scores_list)\n",
    "\n",
    "# Remove the \"Trash\" class from the variables\n",
    "trash_index = 0  # Index of the \"Trash\" class\n",
    "\n",
    "# Remove the Trash column from y_true and y_scores\n",
    "y_true_filtered = np.delete(y_true, trash_index, axis=1)\n",
    "y_scores_filtered = np.delete(y_scores, trash_index, axis=1)\n",
    "\n",
    "# Remove the \"Trash\" class from COCO_CLASSES\n",
    "COCO_CLASSES_FILTERED = {k - 1: v for k, v in COCO_CLASSES.items() if k != trash_index}\n",
    "\n",
    "# Adjust the number of classes\n",
    "num_classes_filtered = numOfClasses - 1\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plot_precision_recall(y_true_filtered, y_scores_filtered, num_classes_filtered, output_dir_plots, COCO_CLASSES_FILTERED)\n",
    "# Plot Confusion Matrix\n",
    "plot_multiclass_confusion_matrix(y_true_filtered, y_scores_filtered, num_classes_filtered, output_dir_plots, COCO_CLASSES_FILTERED)\n",
    "\n",
    "# Completion Message\n",
    "print(\"\\n----- <Testing Completed Successfully> ----- \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
