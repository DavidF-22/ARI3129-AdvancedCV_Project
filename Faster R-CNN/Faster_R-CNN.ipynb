{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note:** For better usability `Training` and `Testing` sections should be placed in seperate source files. Furtheremore some functions like `getModel` are defined twice. Once in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, to install PyTorch the command below was used since it download `PyTroch with Cuda compatability` which allowed the model to run on GPU instead of CPU which `helped decrease execution time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install matplotlib\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image/s to tensor\n",
    "class CocoToTensor:\n",
    "    def __call__(self, image, target):\n",
    "        # Convert PIL image to tensor\n",
    "        image = functional.to_tensor(image)\n",
    "        \n",
    "        # return image and target - target mean the class name and bounding box\n",
    "        return image, target\n",
    "\n",
    "# Load the COCO dataset\n",
    "def get_dataset(img_dir, ann_file):\n",
    "    # Load the COCO dataset\n",
    "    return CocoDetection(\n",
    "        root=img_dir, \n",
    "        annFile=ann_file, \n",
    "        transforms=CocoToTensor()\n",
    "    )\n",
    "\n",
    "# function to load Faster R-CNN with ResNet50 backend\n",
    "def getModel(numOfClasses):\n",
    "    # Load pre-trained Faster R-CNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    input_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(input_features, numOfClasses)\n",
    "    \n",
    "    # Return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training One Epoch Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def trainEpoch(model, optimizer, data_loader, device, epoch):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the data\n",
    "    for batch_index, (images, targets) in enumerate(data_loader):\n",
    "        if (batch_index + 1) == (len(data_loader)):\n",
    "            print(f\"Processing Batch {batch_index + 1}/{len(data_loader)}\\n\")\n",
    "        else:\n",
    "            print(f\"Processing Batch {batch_index + 1}/{len(data_loader)}\", end='\\r')\n",
    "\n",
    "        # Move images to device\n",
    "        images = [img.to(device) for img in images]\n",
    "        \n",
    "        # Validate and process targets\n",
    "        processed_targets = []\n",
    "        valid_images = []\n",
    "        \n",
    "        # Iterate over targets\n",
    "        for i, target in enumerate(targets):\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            \n",
    "            for obj in target:\n",
    "                # Extract bounding box coordinates\n",
    "                bbox = obj['bbox']  # [x, y, width, height]\n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                # Validate width and height are positive\n",
    "                if w > 0 and h > 0:\n",
    "                    boxes.append([x, y, x + w, y + h])  # Convert to [x_min, y_min, x_max, y_max]\n",
    "                    labels.append(obj['category_id'])\n",
    "                    \n",
    "            # If valid boxes\n",
    "            if boxes:\n",
    "                processed_target = {\n",
    "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),  # Corrected key\n",
    "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "                }\n",
    "                processed_targets.append(processed_target)\n",
    "                valid_images.append(images[i])\n",
    "        \n",
    "        # Skip iteration if no valid targets\n",
    "        if not processed_targets:\n",
    "            print(f\"Batch {batch_index + 1}: No valid targets, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure alignment of images and targets\n",
    "        images = valid_images\n",
    "        \n",
    "        # Forward pass\n",
    "        loss_dict = model(images, processed_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch + 1}] Loss: {losses.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset and Creating DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n----- <Loading Training Dataset> -----\")\n",
    "# Load training and validation data\n",
    "training_data = get_dataset(\n",
    "    img_dir='./trashy-dataset-roboflow.coco/train', \n",
    "    ann_file='./trashy-dataset-roboflow.coco/train/_annotations.coco.json'\n",
    ")\n",
    "print(f\"----- <Dataset Loaded Successfully> -----\")\n",
    "\n",
    "# Create two respective dataloaders\n",
    "print(f\"\\n----- <Creating Training DataLoader> -----\")\n",
    "training_dataloader = DataLoader(training_data, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "print(f\"----- <DataLoader Created Successfully> -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Faster R-CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "numOfClasses = 5 # Background, Mixed Waste -Black Bag-, Organic Waste -White Bag-, Other, Recycled Waste -Grey or Green Bag-\n",
    "\n",
    "# Initialise the Model\n",
    "model = getModel(numOfClasses)\n",
    "\n",
    "# Move model to device if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)} is available - moving model to GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"No GPU available. Moving training to CPU.\")\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyperparameters and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and hyperparameters\n",
    "num_epochs = 15\n",
    "parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "optimiser = torch.optim.SGD(parameters, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "learningRate_scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"\\n----- <Training Model> -----\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n----- <Starting Epoch {epoch + 1}/{num_epochs}> -----\")\n",
    "    trainEpoch(model, optimiser, training_dataloader, device, epoch)\n",
    "    learningRate_scheduler.step()\n",
    "    \n",
    "    # Save model's if it's the last epoch\n",
    "    if (epoch + 1) == num_epochs:\n",
    "        # Create output directory if it doesn't exist\n",
    "        outputFolder = './modelOut'\n",
    "        \n",
    "        if not os.path.exists(outputFolder):\n",
    "            os.makedirs(outputFolder)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = f\"{outputFolder}/model_epoch{epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}: Model saved at {model_path}\")\n",
    "    \n",
    "print(f\"\\n----- <Training Completed> -----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load Faster R-CNN with ResNet50 backend\n",
    "def getModel(numOfClasses):\n",
    "    # Load pre-trained Faster R-CNN model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    input_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(input_features, numOfClasses)\n",
    "    \n",
    "    # Return model\n",
    "    return model\n",
    "\n",
    "# function to preprocess image\n",
    "def preprocess_image(img_path, device):\n",
    "    # Open image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Convert image to tensor and add batch dimension\n",
    "    img_tensor = functional.to_tensor(img).unsqueeze(0)\n",
    "    \n",
    "    # move image to device and return it\n",
    "    return img_tensor.to(device)\n",
    "\n",
    "# Get class name\n",
    "def get_class_name(class_id, COCO_CLASSES):\n",
    "    return COCO_CLASSES.get(class_id, 'Unknown') # return 'Unknown' if class_id not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Draw Bounding Boxes on Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding box with correct class name and increase image size\n",
    "def draw_bboxes(output_dir, image, prediction, fig_size, COCO_CLASSES, saved_images_counter, total_images):\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy() # get predicted bounding boxes\n",
    "    labels = prediction[0]['labels'].cpu().numpy() # get predicted labels\n",
    "    scores = prediction[0]['scores'].cpu().numpy() # get predicted scores\n",
    "    \n",
    "    # Set a threshold for showing bounding boxes\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Create a figure and axes using subplots\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw bboxes\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        # check is score is above threshold\n",
    "        if score > threshold:\n",
    "            # Draw bbox\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            # Get class name\n",
    "            class_name = get_class_name(label, COCO_CLASSES)\n",
    "            \n",
    "            # Draw bbox\n",
    "            ax.add_patch(\n",
    "                plt.Rectangle(\n",
    "                    (x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                    fill=False, \n",
    "                    edgecolor='red', \n",
    "                    linewidth=2\n",
    "                )\n",
    "            )\n",
    "            # Add class name\n",
    "            ax.text(\n",
    "                x_min, y_min, \n",
    "                f'{class_name} ({score:.3f})', \n",
    "                color='blue', \n",
    "                fontsize=10,\n",
    "            )\n",
    "            \n",
    "    # Turn off axis\n",
    "    ax.axis('off')\n",
    "    # Saving plt using Image\n",
    "    fig.savefig(f'{output_dir}/{img}', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # ouput saved image number\n",
    "    if (saved_images_counter + 1) == (total_images - 1):\n",
    "        print(f\"Saved image {saved_images_counter + 1}/{total_images - 1}\")\n",
    "    else:\n",
    "        print(f\"Saved image {saved_images_counter + 1}/{total_images - 1}\", end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "fig_size = (8, 8)\n",
    "# Num of classes\n",
    "numOfClasses = 5 # Trash, Mixed Waste -Black Bag-, Organic Waste -White Bag-, Other, Recycled Waste -Grey or Green Bag-\n",
    "# COCO classes - 5 classes\n",
    "COCO_CLASSES = {0:'Trash', 1:'Mixed Waste -Black Bag-', 2:'Organic Waste -White Bag-', 3:'Other', 4:'Recycled Waste -Grey or Green Bag-'}\n",
    "# Get testing directory\n",
    "testing_dir = './trashy-dataset-roboflow.coco/test'\n",
    "# Output directory\n",
    "output_dir = './imagesOut'\n",
    "# saved images counter\n",
    "saved_images_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Device Availability and Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)} is available - moving model to GPU\\n\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"\\nNo GPU available. Moving training to CPU\\n\")\n",
    "\n",
    "# Initialise the Model\n",
    "\n",
    "# Load trained model with weights_only=True\n",
    "model = getModel(numOfClasses)\n",
    "# Load the state dictionary (safe way)\n",
    "state_dict = torch.load('./modelOut/model_epoch15.pth', weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Predictions For Each Test Image and Output To Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output images directory\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get all test images in the directory\n",
    "for img in os.listdir(testing_dir):\n",
    "    # If file is not _annotations.coco.json\n",
    "    if not img == '_annotations.coco.json':\n",
    "        # Get full image path\n",
    "        img_path = os.path.join(testing_dir, img)\n",
    "        # Convert image to tensor\n",
    "        image_tensor = preprocess_image(img_path, device)\n",
    "\n",
    "        # Disable gradient computation\n",
    "        with torch.no_grad():\n",
    "            # Get prediction\n",
    "            prediction = model(image_tensor)   \n",
    "    \n",
    "        # Display image with bounding boxes\n",
    "        draw_bboxes(output_dir, Image.open(img_path), prediction, fig_size, COCO_CLASSES, saved_images_counter, total_images=len(os.listdir(testing_dir)))\n",
    "        # Increment saved images counter\n",
    "        saved_images_counter += 1\n",
    "        \n",
    "        # Close all figures\n",
    "        plt.close('all')\n",
    "        \n",
    "print(\"\\n----- <Testing Completed> ----- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall and Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
